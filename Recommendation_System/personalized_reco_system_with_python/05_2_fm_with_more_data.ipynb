{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding  0  cases...\n",
      "Encoding  10000  cases...\n",
      "Encoding  20000  cases...\n",
      "Encoding  30000  cases...\n",
      "Encoding  40000  cases...\n",
      "Encoding  50000  cases...\n",
      "Encoding  60000  cases...\n",
      "Encoding  70000  cases...\n",
      "Encoding  80000  cases...\n",
      "Encoding  90000  cases...\n"
     ]
    }
   ],
   "source": [
    "# Factorizagion Machines(FM) 구현 - 추가변수 사용\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the u.user file into a dataframe\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('./ml-100k/u.user', sep='|', names=u_cols, encoding='latin-1')\n",
    "\n",
    "# Load the u.item file into a dataframe\n",
    "i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL', \n",
    "          'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', \n",
    "          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n",
    "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies = pd.read_csv('./ml-100k/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "# Load the u.data file into a dataframe\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./ml-100k/u.data', sep='\\t', names=r_cols, encoding='latin-1') \n",
    "\n",
    "# User encoding\n",
    "user_dict = {}\n",
    "for i in set(users['user_id']):\n",
    "    user_dict[i] = len(user_dict)\n",
    "n_user = len(user_dict)\n",
    "# Item encoding\n",
    "item_dict = {}\n",
    "start_point = n_user\n",
    "for i in set(movies['movie_id']):\n",
    "    item_dict[i] = start_point + len(item_dict)\n",
    "n_item = len(item_dict)\n",
    "start_point += n_item\n",
    "# Occupation encoding\n",
    "occ_dict = {}\n",
    "for i in set(users['occupation']):\n",
    "    occ_dict[i] = start_point + len(occ_dict)\n",
    "n_occ = len(occ_dict)\n",
    "start_point += n_occ\n",
    "# Gender encoding\n",
    "gender_dict = {}\n",
    "for i in set(users['sex']):\n",
    "    gender_dict[i] = start_point + len(gender_dict)\n",
    "n_gender = len(gender_dict)\n",
    "start_point += n_gender\n",
    "# Genre encoding\n",
    "genre_dict = {}\n",
    "genre = ['unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', \n",
    "          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \n",
    "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "for i in genre:\n",
    "    genre_dict[i] = start_point + len(genre_dict)\n",
    "n_genre = len(genre_dict)\n",
    "start_point += n_genre\n",
    "age_index = start_point\n",
    "start_point += 1\n",
    "num_x = start_point             # Total number of x\n",
    "   \n",
    "# Merge data\n",
    "movies = movies.drop(['title', 'release date', 'video release date', 'IMDB URL'], axis=1)\n",
    "users = users.drop(['zip_code'], axis=1)\n",
    "ratings = ratings.drop(['timestamp'], axis=1)\n",
    "x = pd.merge(ratings, movies, how='outer', on='movie_id')\n",
    "x = pd.merge(x, users, how='outer', on='user_id')\n",
    "x = shuffle(x, random_state=1)\n",
    "\n",
    "# Generate X data\n",
    "data = []\n",
    "y = []\n",
    "age_mean = np.mean(x['age'])\n",
    "age_std = np.std(x['age'])\n",
    "w0 = np.mean(x['rating'])\n",
    "for i in range(len(x)):\n",
    "    case = x.iloc[i]\n",
    "    x_index = []\n",
    "    x_value = []\n",
    "    x_index.append(user_dict[case['user_id']])     # User id encoding\n",
    "    x_value.append(1)\n",
    "    x_index.append(item_dict[case['movie_id']])    # Movie id encoding\n",
    "    x_value.append(1)\n",
    "    x_index.append(occ_dict[case['occupation']])   # Occupation id encoding\n",
    "    x_value.append(1)\n",
    "    x_index.append(gender_dict[case['sex']])       # Gender id encoding\n",
    "    x_value.append(1)\n",
    "    for j in genre:\n",
    "        if case[j] == 1:               # 해당 장르가 1 \n",
    "            x_index.append(genre_dict[j])\n",
    "            x_value.append(1)\n",
    "    x_index.append(age_index)\n",
    "    x_value.append((case['age'] - age_mean) / age_std)\n",
    "    data.append([x_index, x_value])\n",
    "    y.append(case['rating'] - w0)\n",
    "    if (i % 10000) == 0:\n",
    "        print('Encoding ', i, ' cases...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))\n",
    "\n",
    "\n",
    "class FM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        N,\n",
    "        K,\n",
    "        data,\n",
    "        y,\n",
    "        alpha,\n",
    "        beta,\n",
    "        train_ratio=0.75,\n",
    "        iterations=100,\n",
    "        tolerance=0.005,\n",
    "        l2_reg=True,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        self.K = K  # Number of latent factors\n",
    "        self.N = N  # Number of x (variables)\n",
    "        self.n_cases = len(data)  # N of observations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.l2_reg = l2_reg\n",
    "        self.tolerance = tolerance\n",
    "        self.verbose = verbose\n",
    "        # w 초기화\n",
    "        self.w = np.random.normal(scale=1.0 / self.N, size=(self.N))\n",
    "        # v 초기화\n",
    "        self.v = np.random.normal(scale=1.0 / self.K, size=(self.N, self.K))\n",
    "        # Train/Test 분리\n",
    "        cutoff = int(train_ratio * len(data))\n",
    "        self.train_x = data[:cutoff]\n",
    "        self.test_x = data[cutoff:]\n",
    "        self.train_y = y[:cutoff]\n",
    "        self.test_y = y[cutoff:]\n",
    "\n",
    "    def test(self):  # Training 하면서 RMSE 계산\n",
    "        # SGD를 iterations 숫자만큼 수행\n",
    "        best_RMSE = 10000\n",
    "        best_iteration = 0\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            rmse1 = self.sgd(self.train_x, self.train_y)  # SGD & Train RMSE 계산\n",
    "            rmse2 = self.test_rmse(self.test_x, self.test_y)  # Test RMSE 계산\n",
    "            training_process.append((i, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\"\n",
    "                        % (i + 1, rmse1, rmse2)\n",
    "                    )\n",
    "            if best_RMSE > rmse2:  # New best record\n",
    "                best_RMSE = rmse2\n",
    "                best_iteration = i\n",
    "            elif (\n",
    "                rmse2 - best_RMSE\n",
    "            ) > self.tolerance:  # RMSE is increasing over tolerance\n",
    "                break\n",
    "        print(best_iteration, best_RMSE)\n",
    "        return training_process\n",
    "\n",
    "    # w, v 업데이트를 위한 Stochastic gradient descent\n",
    "    def sgd(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data, y in zip(x_data, y_data):\n",
    "            x_idx = data[0]\n",
    "            x_0 = np.array(data[1])  # xi axis=0 [1, 2, 3]\n",
    "            x_1 = x_0.reshape(-1, 1)  # xi axis=1 [[1], [2], [3]]\n",
    "\n",
    "            # biases\n",
    "            bias_score = np.sum(self.w[x_idx] * x_0)\n",
    "\n",
    "            # score 계산\n",
    "            vx = self.v[x_idx] * (x_1)  # v matrix * x\n",
    "            sum_vx = np.sum(vx, axis=0)  # sigma(vx)\n",
    "            sum_vx_2 = np.sum(vx * vx, axis=0)  # ( v matrix * x )의 제곱\n",
    "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "            # 예측값 계산\n",
    "            y_hat = bias_score + latent_score\n",
    "            y_pred.append(y_hat)\n",
    "            error = y - y_hat\n",
    "            # w, v 업데이트\n",
    "            if self.l2_reg:  # regularization이 있는 경우\n",
    "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
    "                self.v[x_idx] += (\n",
    "                    error\n",
    "                    * self.alpha\n",
    "                    * ((x_1) * sum(vx) - (vx * x_1) - self.beta * self.v[x_idx])\n",
    "                )\n",
    "            else:  # regularization이 없는 경우\n",
    "                self.w[x_idx] += error * self.alpha * x_0\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1))\n",
    "        return RMSE(y_data, y_pred)\n",
    "\n",
    "    def test_rmse(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data, y in zip(x_data, y_data):\n",
    "            y_hat = self.predict(data[0], data[1])\n",
    "            y_pred.append(y_hat)\n",
    "        return RMSE(y_data, y_pred)\n",
    "\n",
    "    def predict(self, idx, x):\n",
    "        x_0 = np.array(x)\n",
    "        x_1 = x_0.reshape(-1, 1)\n",
    "\n",
    "        # biases\n",
    "        bias_score = np.sum(self.w[idx] * x_0)\n",
    "\n",
    "        # score 계산\n",
    "        vx = self.v[idx] * (x_1)\n",
    "        sum_vx = np.sum(vx, axis=0)\n",
    "        sum_vx_2 = np.sum(vx * vx, axis=0)\n",
    "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "        # 예측값 계산\n",
    "        y_hat = bias_score + latent_score\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 1.077308 ; Test RMSE = 1.080376\n",
      "Iteration: 20 ; Train RMSE = 1.052522 ; Test RMSE = 1.057360\n",
      "Iteration: 30 ; Train RMSE = 1.025650 ; Test RMSE = 1.033081\n",
      "Iteration: 40 ; Train RMSE = 0.997986 ; Test RMSE = 1.009286\n",
      "Iteration: 50 ; Train RMSE = 0.973718 ; Test RMSE = 0.989499\n",
      "Iteration: 60 ; Train RMSE = 0.955133 ; Test RMSE = 0.975197\n",
      "Iteration: 70 ; Train RMSE = 0.941534 ; Test RMSE = 0.965334\n",
      "Iteration: 80 ; Train RMSE = 0.931373 ; Test RMSE = 0.958440\n",
      "Iteration: 90 ; Train RMSE = 0.923541 ; Test RMSE = 0.953541\n",
      "Iteration: 100 ; Train RMSE = 0.917339 ; Test RMSE = 0.950018\n",
      "Iteration: 110 ; Train RMSE = 0.912297 ; Test RMSE = 0.947444\n",
      "Iteration: 120 ; Train RMSE = 0.908086 ; Test RMSE = 0.945519\n",
      "Iteration: 130 ; Train RMSE = 0.904470 ; Test RMSE = 0.944041\n",
      "Iteration: 140 ; Train RMSE = 0.901281 ; Test RMSE = 0.942870\n",
      "Iteration: 150 ; Train RMSE = 0.898403 ; Test RMSE = 0.941916\n",
      "Iteration: 160 ; Train RMSE = 0.895752 ; Test RMSE = 0.941120\n",
      "Iteration: 170 ; Train RMSE = 0.893270 ; Test RMSE = 0.940441\n",
      "Iteration: 180 ; Train RMSE = 0.890916 ; Test RMSE = 0.939853\n",
      "Iteration: 190 ; Train RMSE = 0.888665 ; Test RMSE = 0.939341\n",
      "Iteration: 200 ; Train RMSE = 0.886497 ; Test RMSE = 0.938894\n",
      "Iteration: 210 ; Train RMSE = 0.884402 ; Test RMSE = 0.938505\n",
      "Iteration: 220 ; Train RMSE = 0.882372 ; Test RMSE = 0.938172\n",
      "Iteration: 230 ; Train RMSE = 0.880405 ; Test RMSE = 0.937891\n",
      "Iteration: 240 ; Train RMSE = 0.878496 ; Test RMSE = 0.937662\n",
      "Iteration: 250 ; Train RMSE = 0.876646 ; Test RMSE = 0.937481\n",
      "Iteration: 260 ; Train RMSE = 0.874851 ; Test RMSE = 0.937346\n",
      "Iteration: 270 ; Train RMSE = 0.873112 ; Test RMSE = 0.937256\n",
      "Iteration: 280 ; Train RMSE = 0.871426 ; Test RMSE = 0.937207\n",
      "Iteration: 290 ; Train RMSE = 0.869791 ; Test RMSE = 0.937196\n",
      "Iteration: 300 ; Train RMSE = 0.868205 ; Test RMSE = 0.937219\n",
      "Iteration: 310 ; Train RMSE = 0.866664 ; Test RMSE = 0.937273\n",
      "287 0.9371952086948906\n"
     ]
    }
   ],
   "source": [
    "K = 200\n",
    "fm1 = FM(\n",
    "    num_x,\n",
    "    K,\n",
    "    data,\n",
    "    y,\n",
    "    alpha=0.00005,\n",
    "    beta=0.002,\n",
    "    train_ratio=0.75,\n",
    "    iterations=900,\n",
    "    tolerance=0.0001,\n",
    "    l2_reg=True,\n",
    "    verbose=True,\n",
    ")\n",
    "result = fm1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
