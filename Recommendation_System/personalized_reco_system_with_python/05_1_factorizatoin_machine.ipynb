{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding  0  cases...\n",
      "Encoding  10000  cases...\n",
      "Encoding  20000  cases...\n",
      "Encoding  30000  cases...\n",
      "Encoding  40000  cases...\n",
      "Encoding  50000  cases...\n",
      "Encoding  60000  cases...\n",
      "Encoding  70000  cases...\n",
      "Encoding  80000  cases...\n",
      "Encoding  90000  cases...\n"
     ]
    }
   ],
   "source": [
    "# Factorizagion Machines(FM) 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the u.data file into a dataframe\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('./ml-100k/u.data', sep='\\t', names=r_cols, encoding='latin-1') \n",
    "\n",
    "# User encoding\n",
    "user_dict = {}\n",
    "for i in set(ratings['user_id']):\n",
    "    user_dict[i] = len(user_dict)\n",
    "n_user = len(user_dict)\n",
    "# Item encoding\n",
    "item_dict = {}\n",
    "start_point = n_user\n",
    "for i in set(ratings['movie_id']):\n",
    "    item_dict[i] = start_point + len(item_dict)\n",
    "n_item = len(item_dict)\n",
    "start_point += n_item\n",
    "num_x = start_point               # Total number of x\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "\n",
    "# Generate X data\n",
    "data = []\n",
    "y = []\n",
    "w0 = np.mean(ratings['rating'])\n",
    "for i in range(len(ratings)):\n",
    "    case = ratings.iloc[i]\n",
    "    x_index = []\n",
    "    x_value = []\n",
    "    x_index.append(user_dict[case['user_id']])     # User id encoding\n",
    "    x_value.append(1)\n",
    "    x_index.append(item_dict[case['movie_id']])    # Movie id encoding\n",
    "    x_value.append(1)\n",
    "    data.append([x_index, x_value])\n",
    "    y.append(case['rating'] - w0)\n",
    "    if (i % 10000) == 0:\n",
    "        print('Encoding ', i, ' cases...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred)) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        N,\n",
    "        K,\n",
    "        data,\n",
    "        y,\n",
    "        alpha,\n",
    "        beta,\n",
    "        train_ratio=0.75,\n",
    "        iterations=100,\n",
    "        tolerance=0.005,\n",
    "        l2_reg=True,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        self.K = K  # Number of latent factors\n",
    "        self.N = N  # Number of x (variables)\n",
    "        self.n_cases = len(data)  # N of observations\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.l2_reg = l2_reg\n",
    "        self.tolerance = tolerance\n",
    "        self.verbose = verbose\n",
    "        # w 초기화\n",
    "        self.w = np.random.normal(scale=1.0 / self.N, size=(self.N))\n",
    "        # v 초기화\n",
    "        self.v = np.random.normal(scale=1.0 / self.K, size=(self.N, self.K))\n",
    "        # Train/Test 분리\n",
    "        cutoff = int(train_ratio * len(data))\n",
    "        self.train_x = data[:cutoff]\n",
    "        self.test_x = data[cutoff:]\n",
    "        self.train_y = y[:cutoff]\n",
    "        self.test_y = y[cutoff:]\n",
    "\n",
    "    def test(self):  # Training 하면서 RMSE 계산\n",
    "        # SGD를 iterations 숫자만큼 수행\n",
    "        best_RMSE = 10000\n",
    "        best_iteration = 0\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            rmse1 = self.sgd(self.train_x, self.train_y)  # SGD & Train RMSE 계산\n",
    "            rmse2 = self.test_rmse(self.test_x, self.test_y)  # Test RMSE 계산\n",
    "            training_process.append((i, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration: %d ; Train RMSE = %.6f ; Test RMSE = %.6f\"\n",
    "                        % (i + 1, rmse1, rmse2)\n",
    "                    )\n",
    "            if best_RMSE > rmse2:  # New best record\n",
    "                best_RMSE = rmse2\n",
    "                best_iteration = i\n",
    "            elif (\n",
    "                rmse2 - best_RMSE\n",
    "            ) > self.tolerance:  # RMSE is increasing over tolerance\n",
    "                break\n",
    "        print(best_iteration, best_RMSE)\n",
    "        return training_process\n",
    "\n",
    "    # w, v 업데이트를 위한 Stochastic gradient descent\n",
    "    def sgd(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data, y in zip(x_data, y_data):\n",
    "            x_idx = data[0]\n",
    "            x_0 = np.array(data[1])  # xi axis=0 [1, 2, 3]\n",
    "            x_1 = x_0.reshape(-1, 1)  # xi axis=1 [[1], [2], [3]]\n",
    "\n",
    "            # biases\n",
    "            bias_score = np.sum(self.w[x_idx] * x_0)\n",
    "\n",
    "            # score 계산\n",
    "            vx = self.v[x_idx] * (x_1)  # v matrix * x\n",
    "            sum_vx = np.sum(vx, axis=0)  # sigma(vx)\n",
    "            sum_vx_2 = np.sum(vx * vx, axis=0)  # ( v matrix * x )의 제곱\n",
    "            latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "            # 예측값 계산\n",
    "            y_hat = bias_score + latent_score\n",
    "            y_pred.append(y_hat)\n",
    "            error = y - y_hat\n",
    "            # w, v 업데이트\n",
    "            if self.l2_reg:  # regularization이 있는 경우\n",
    "                self.w[x_idx] += error * self.alpha * (x_0 - self.beta * self.w[x_idx])\n",
    "                self.v[x_idx] += (\n",
    "                    error\n",
    "                    * self.alpha\n",
    "                    * ((x_1) * sum(vx) - (vx * x_1) - self.beta * self.v[x_idx])\n",
    "                )\n",
    "            else:  # regularization이 없는 경우\n",
    "                self.w[x_idx] += error * self.alpha * x_0\n",
    "                self.v[x_idx] += error * self.alpha * ((x_1) * sum(vx) - (vx * x_1))\n",
    "        return RMSE(y_data, y_pred)\n",
    "\n",
    "    def test_rmse(self, x_data, y_data):\n",
    "        y_pred = []\n",
    "        for data, y in zip(x_data, y_data):\n",
    "            y_hat = self.predict(data[0], data[1])\n",
    "            y_pred.append(y_hat)\n",
    "        return RMSE(y_data, y_pred)\n",
    "\n",
    "    def predict(self, idx, x):\n",
    "        x_0 = np.array(x)\n",
    "        x_1 = x_0.reshape(-1, 1)\n",
    "\n",
    "        # biases\n",
    "        bias_score = np.sum(self.w[idx] * x_0)\n",
    "\n",
    "        # score 계산\n",
    "        vx = self.v[idx] * (x_1)\n",
    "        sum_vx = np.sum(vx, axis=0)\n",
    "        sum_vx_2 = np.sum(vx * vx, axis=0)\n",
    "        latent_score = 0.5 * np.sum(np.square(sum_vx) - sum_vx_2)\n",
    "\n",
    "        # 예측값 계산\n",
    "        y_hat = bias_score + latent_score\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.955976 ; Test RMSE = 0.972694\n",
      "Iteration: 20 ; Train RMSE = 0.934230 ; Test RMSE = 0.957412\n",
      "Iteration: 30 ; Train RMSE = 0.925388 ; Test RMSE = 0.951438\n",
      "Iteration: 40 ; Train RMSE = 0.920594 ; Test RMSE = 0.948412\n",
      "Iteration: 50 ; Train RMSE = 0.917475 ; Test RMSE = 0.946657\n",
      "Iteration: 60 ; Train RMSE = 0.914945 ; Test RMSE = 0.945467\n",
      "Iteration: 70 ; Train RMSE = 0.912164 ; Test RMSE = 0.944394\n",
      "Iteration: 80 ; Train RMSE = 0.908018 ; Test RMSE = 0.942940\n",
      "Iteration: 90 ; Train RMSE = 0.900755 ; Test RMSE = 0.940381\n",
      "Iteration: 100 ; Train RMSE = 0.888400 ; Test RMSE = 0.936030\n",
      "Iteration: 110 ; Train RMSE = 0.870569 ; Test RMSE = 0.930268\n",
      "Iteration: 120 ; Train RMSE = 0.848549 ; Test RMSE = 0.924482\n",
      "Iteration: 130 ; Train RMSE = 0.822671 ; Test RMSE = 0.919421\n",
      "Iteration: 140 ; Train RMSE = 0.792261 ; Test RMSE = 0.915292\n",
      "Iteration: 150 ; Train RMSE = 0.757162 ; Test RMSE = 0.912423\n",
      "Iteration: 160 ; Train RMSE = 0.718225 ; Test RMSE = 0.911137\n",
      "Iteration: 170 ; Train RMSE = 0.676778 ; Test RMSE = 0.911500\n",
      "162 0.9110774434373848\n"
     ]
    }
   ],
   "source": [
    "K = 350\n",
    "fm1 = FM(\n",
    "    num_x,\n",
    "    K,\n",
    "    data,\n",
    "    y,\n",
    "    alpha=0.0014,\n",
    "    beta=0.075,\n",
    "    train_ratio=0.75,\n",
    "    iterations=600,\n",
    "    tolerance=0.0005,\n",
    "    l2_reg=True,\n",
    "    verbose=True,\n",
    ")\n",
    "result = fm1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
