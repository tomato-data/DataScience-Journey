{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse matrix로 MovieLens 20m 분석\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "# 20M data 읽어오기\n",
    "ratings = pd.read_csv(\n",
    "    \"./ml-100k/ratings-20m.csv\", names=r_cols, sep=\",\", encoding=\"latin-1\"\n",
    ")\n",
    "ratings = ratings[[\"user_id\", \"movie_id\", \"rating\"]].astype(int)  # timestamp 제거\n",
    "\n",
    "# train test 분리\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]\n",
    "\n",
    "##### Sparse matrix 사용 >>>>>>>>>>>>>>>>>>\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "data = np.array(ratings[\"rating\"])\n",
    "row_indices = np.array(ratings[\"user_id\"])\n",
    "col_indices = np.array(ratings[\"movie_id\"])\n",
    "ratings = csr_matrix((data, (row_indices, col_indices)), dtype=int)\n",
    "# <<<<<<<<<<<<<<< Sparse matrix 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New MF class for training & testing\n",
    "class NEW_MF:\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = ratings\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = (\n",
    "            self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        )\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = r - prediction\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):  # test 데이터에 있는 각 데이터에 대해서\n",
    "            x, y, z = ratings_test.iloc[i]  # user_id, item_id, rating 가져오기\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0  # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set  # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error / len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1.0 / self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1.0 / self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i + 1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\"\n",
    "                        % (i + 1, rmse1, rmse2)\n",
    "                    )\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(user_id, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m mf \u001b[38;5;241m=\u001b[39m NEW_MF(R_temp, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m190\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m test_set \u001b[38;5;241m=\u001b[39m mf\u001b[38;5;241m.\u001b[39mset_test(ratings_test)\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mNEW_MF.test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# List of training samples\u001b[39;00m\n\u001b[1;32m     74\u001b[0m rows, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m [(i, j, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR[i, j]) \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(rows, columns)]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Stochastic gradient descent for given number of iterations\u001b[39;00m\n\u001b[1;32m     78\u001b[0m training_process \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# List of training samples\u001b[39;00m\n\u001b[1;32m     74\u001b[0m rows, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mR\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m [(i, j, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(rows, columns)]\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Stochastic gradient descent for given number of iterations\u001b[39;00m\n\u001b[1;32m     78\u001b[0m training_process \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-env/lib/python3.8/site-packages/scipy/sparse/_index.py:52\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, INT_TYPES):\n\u001b[0;32m---> 52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_intXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_1d_array_slice()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-env/lib/python3.8/site-packages/scipy/sparse/_compressed.py:660\u001b[0m, in \u001b[0;36m_cs_matrix._get_intXint\u001b[0;34m(self, row, col)\u001b[0m\n\u001b[1;32m    656\u001b[0m major, minor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((row, col))\n\u001b[1;32m    657\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m get_csr_submatrix(\n\u001b[1;32m    658\u001b[0m     M, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m    659\u001b[0m     major, major \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, minor, minor \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tf-env/lib/python3.8/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Testing MF RMSE\n",
    "R_temp = ratings.copy()\n",
    "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=190, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
