{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬요인화(MF) - Train/Test 분리\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "r_cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    \"./ml-100k/u.data\", names=r_cols, sep=\"\\t\", encoding=\"latin-1\"\n",
    ")\n",
    "ratings = ratings[[\"user_id\", \"movie_id\", \"rating\"]].astype(int)  # timestamp 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New MF class for training & testing\n",
    "class NEW_MF:\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings)\n",
    "        ##### >>>>> (2) user_id, item_id를 R의 index와 매핑하기 위한 dictionary 생성\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "        #### <<<<< (2)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = (\n",
    "            self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        )\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = r - prediction\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i, :])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j, :])\n",
    "\n",
    "    ##### >>>>> (3)\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):  # test 데이터에 있는 각 데이터에 대해서\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0  # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set  # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error / len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1.0 / self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1.0 / self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i + 1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\"\n",
    "                        % (i + 1, rmse1, rmse2)\n",
    "                    )\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(\n",
    "            self.user_id_index[user_id], self.item_id_index[item_id]\n",
    "        )\n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return (\n",
    "            self.b\n",
    "            + self.b_u[:, np.newaxis]\n",
    "            + self.b_d[np.newaxis, :]\n",
    "            + self.P.dot(self.Q.T)\n",
    "        )\n",
    "\n",
    "\n",
    "##### <<<<< (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9659 ; Test RMSE = 0.9834\n",
      "Iteration: 20 ; Train RMSE = 0.9410 ; Test RMSE = 0.9645\n",
      "Iteration: 30 ; Train RMSE = 0.9298 ; Test RMSE = 0.9566\n",
      "Iteration: 40 ; Train RMSE = 0.9230 ; Test RMSE = 0.9523\n",
      "Iteration: 50 ; Train RMSE = 0.9183 ; Test RMSE = 0.9496\n",
      "Iteration: 60 ; Train RMSE = 0.9144 ; Test RMSE = 0.9477\n",
      "Iteration: 70 ; Train RMSE = 0.9106 ; Test RMSE = 0.9462\n",
      "Iteration: 80 ; Train RMSE = 0.9064 ; Test RMSE = 0.9447\n",
      "Iteration: 90 ; Train RMSE = 0.9012 ; Test RMSE = 0.9431\n",
      "Iteration: 100 ; Train RMSE = 0.8945 ; Test RMSE = 0.9410\n",
      "[[3.74848262 3.37034646 3.0617788  ... 3.36274278 3.45639603 3.47250255]\n",
      " [3.89805395 3.49129002 3.11861408 ... 3.4410111  3.5470898  3.55439958]\n",
      " [3.33794338 2.88497424 2.53519301 ... 2.82080945 2.94234044 2.93944035]\n",
      " ...\n",
      " [4.22920018 3.7770487  3.44020472 ... 3.71893366 3.82406039 3.83406692]\n",
      " [4.35576741 3.88953168 3.57792934 ... 3.83085527 3.94562007 3.93397369]\n",
      " [3.84419952 3.37629022 3.0184947  ... 3.3158461  3.40840724 3.39962797]]\n",
      "3.3703464577079796\n"
     ]
    }
   ],
   "source": [
    "# Testing MF RMSE\n",
    "R_temp = ratings.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\").fillna(0)\n",
    "mf = NEW_MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()\n",
    "\n",
    "# Printing predictions\n",
    "print(mf.full_prediction())\n",
    "print(mf.get_one_prediction(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4-1.ipynb에서 train/test set을 분리하는 방법을 shuffle() 대신에 앞 장에서 사용한 train_test_split()을 사용해서 분리하도록 수정하고 실행해 보세요. 실행 결과 RMSE에 차이가 많이 난다면 왜 차이가 발생했을지 설명하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
