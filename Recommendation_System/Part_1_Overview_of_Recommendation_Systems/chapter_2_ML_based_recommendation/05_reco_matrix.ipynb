{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_pred, k):\n",
    "    return float(np.in1d(y_pred[:k], y_true).mean())\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k):\n",
    "    return float(np.in1d(y_true, y_pred[:k]).mean())\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k):\n",
    "    r = np.inid(y_pred[:k], y_true)\n",
    "    discount = 1 / (np.log2(np.arange(r.shape[0]) + 2))\n",
    "    dcg = np.sum(r * discount)\n",
    "    idcg = np.sum(np.ones_list(r) * discount)\n",
    "    return float(dcg / idcg)\n",
    "\n",
    "def average_precision_at_k(y_true, y_pred, k):\n",
    "    r = np.in1d(y_pred[:k], y_true)\n",
    "    if 0 < np.sum(r):\n",
    "        return float(np.sum(np.cumsum(r) / (np.arange(len(r))+1)*r)/np.sum(r))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def rr_at_k(y_true, y_pred, k):\n",
    "    r = np.in1d(y_pred[:k], y_true)\n",
    "    return max(r / len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1, 2, 3, 4, 5]\n",
    "y_true = [2, 7, 3]\n",
    "k = 3\n",
    "r = np.in1d(y_pred[:k], y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.arange(len(r)) + 1) * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1666666666666665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.cumsum(r) / (np.arange(len(r)) + 1) * r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interacted items for the first user: [8 1 5 0 7]\n",
      "Recommended items for the first user: [8 2 5 7 3]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_users = 5\n",
    "num_items = 10\n",
    "interactions_per_user = 5\n",
    "recommended_items_per_user = 5\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "interaction_data = [\n",
    "    np.random.choice(num_items, size=interactions_per_user, replace=False)\n",
    "    for _ in range(num_users)\n",
    "]\n",
    "\n",
    "# 샘플 예측 데이터 생성\n",
    "prediction_data = [\n",
    "    np.random.choice(num_items, size=recommended_items_per_user, replace=False)\n",
    "    for _ in range(num_users)\n",
    "]\n",
    "\n",
    "# 예시 출력\n",
    "print(\"Interacted items for the first user:\", interaction_data[0])\n",
    "print(\"Recommended items for the first user:\", prediction_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_pred, k):\n",
    "    # 예측 된 아이템 중 상위 k개만\n",
    "    y_pred = y_pred[:k]\n",
    "    # top-k item 중 유관 상품의 비율\n",
    "    return len(set(y_true) & set(y_pred)) / k\n",
    "\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k):\n",
    "    # 예측 된 아이템 중 상위 k개만\n",
    "    y_pred = y_pred[:k]\n",
    "    # 실제 유관 상품 중 상위 k개에 포함된 비율\n",
    "    return len(set(y_true) & set(y_pred)) / len(y_true)\n",
    "\n",
    "\n",
    "def mrr_at_k(y_true, y_pred, k):\n",
    "    # 예측 된 아이템 중 상위 k개만\n",
    "    y_pred = y_pred[:k]\n",
    "    for i, p in enumerate(y_pred):\n",
    "        if p in y_true:\n",
    "            return 1 / (i + 1)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def average_precision_at_k(y_true, y_pred, k):\n",
    "    # 예측 된 아이템 중 상위 k개만\n",
    "    y_pred = y_pred[:k]\n",
    "    # average precision at k\n",
    "    score = 0.0\n",
    "    num_hits = 0\n",
    "    for i, p in enumerate(y_pred):\n",
    "        if p in y_true:\n",
    "            num_hits += 1\n",
    "            score += num_hits / (i + 1)\n",
    "    return score / min(len(y_true), k)\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k):\n",
    "    # 예측 된 아이템 중 상위 k개만\n",
    "    y_pred = y_pred[:k]\n",
    "    # DCG at k\n",
    "    dcg = sum([int(p in y_true) / np.log2(i + 2) for i, p in enumerate(y_pred)])\n",
    "    # IDCG at k\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(y_true), k))])\n",
    "    # NDCG at k\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for user 1:\n",
      "true items of user 1: [8 1 5 0 7]\n",
      "reco items of user 1: [8 2 5 7 3]\n",
      "Precision@3 = 0.6666666666666666\n",
      "Recall@3 = 0.4\n",
      "MAP@3 = 0.5555555555555555\n",
      "NDCG@3 = 0.7039180890341347\n",
      "MRR@3 = 1.0\n",
      "\n",
      "Metrics for user 2:\n",
      "true items of user 2: [0 1 8 5 3]\n",
      "reco items of user 2: [0 5 2 6 3]\n",
      "Precision@3 = 0.6666666666666666\n",
      "Recall@3 = 0.4\n",
      "MAP@3 = 0.6666666666666666\n",
      "NDCG@3 = 0.7653606369886217\n",
      "MRR@3 = 1.0\n",
      "\n",
      "Metrics for user 3:\n",
      "true items of user 3: [9 2 0 6 8]\n",
      "reco items of user 3: [4 8 1 3 0]\n",
      "Precision@3 = 0.3333333333333333\n",
      "Recall@3 = 0.2\n",
      "MAP@3 = 0.16666666666666666\n",
      "NDCG@3 = 0.2960819109658652\n",
      "MRR@3 = 0.5\n",
      "\n",
      "Metrics for user 4:\n",
      "true items of user 4: [1 7 6 2 8]\n",
      "reco items of user 4: [2 0 4 9 8]\n",
      "Precision@3 = 0.3333333333333333\n",
      "Recall@3 = 0.2\n",
      "MAP@3 = 0.3333333333333333\n",
      "NDCG@3 = 0.46927872602275644\n",
      "MRR@3 = 1.0\n",
      "\n",
      "Metrics for user 5:\n",
      "true items of user 5: [1 5 4 8 0]\n",
      "reco items of user 5: [4 2 7 0 6]\n",
      "Precision@3 = 0.3333333333333333\n",
      "Recall@3 = 0.2\n",
      "MAP@3 = 0.3333333333333333\n",
      "NDCG@3 = 0.46927872602275644\n",
      "MRR@3 = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 3  # We will compute the metrics at 3\n",
    "\n",
    "# For each user, compute and print the metrics\n",
    "for i in range(num_users):\n",
    "    y_true = interaction_data[i]\n",
    "    y_pred = prediction_data[i]\n",
    "\n",
    "    precision = precision_at_k(y_true, y_pred, k)\n",
    "    recall = recall_at_k(y_true, y_pred, k)\n",
    "    map_ = average_precision_at_k(y_true, y_pred, k)\n",
    "    ndcg = ndcg_at_k(y_true, y_pred, k)\n",
    "    mrr = mrr_at_k(y_true, y_pred, k)\n",
    "\n",
    "    print(f\"Metrics for user {i+1}:\")\n",
    "    print(f\"true items of user {i+1}: {y_true}\")\n",
    "    print(f\"reco items of user {i+1}: {y_pred}\")\n",
    "    print(f\"Precision@{k} = {precision}\")\n",
    "    print(f\"Recall@{k} = {recall}\")\n",
    "    print(f\"MAP@{k} = {map_}\")\n",
    "    print(f\"NDCG@{k} = {ndcg}\")\n",
    "    print(f\"MRR@{k} = {mrr}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for user 5:\n",
      "true items of user 5: [1, 2, 3]\n",
      "reco items of user 5: [1, 2, 3, 4, 5]\n",
      "Precision@3 = 1.0\n",
      "Recall@3 = 1.0\n",
      "MAP@3 = 1.0\n",
      "NDCG@3 = 1.0\n",
      "MRR@3 = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이상적인 추천 점수\n",
    "\n",
    "y_true = [1, 2, 3]\n",
    "y_pred = [1, 2, 3, 4, 5]\n",
    "\n",
    "precision = precision_at_k(y_true, y_pred, k)\n",
    "recall = recall_at_k(y_true, y_pred, k)\n",
    "map_ = average_precision_at_k(y_true, y_pred, k)\n",
    "ndcg = ndcg_at_k(y_true, y_pred, k)\n",
    "mrr = mrr_at_k(y_true, y_pred, k)\n",
    "\n",
    "print(f\"Metrics for user {i+1}:\")\n",
    "print(f\"true items of user {i+1}: {y_true}\")\n",
    "print(f\"reco items of user {i+1}: {y_pred}\")\n",
    "print(f\"Precision@{k} = {precision}\")\n",
    "print(f\"Recall@{k} = {recall}\")\n",
    "print(f\"MAP@{k} = {map_}\")\n",
    "print(f\"NDCG@{k} = {ndcg}\")\n",
    "print(f\"MRR@{k} = {mrr}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for user 5:\n",
      "true items of user 5: [1, 2, 3]\n",
      "reco items of user 5: [1, 2, 4, 3, 5]\n",
      "Precision@3 = 0.6666666666666666\n",
      "Recall@3 = 0.6666666666666666\n",
      "MAP@3 = 0.6666666666666666\n",
      "NDCG@3 = 0.7653606369886217\n",
      "MRR@3 = 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 약간 아쉬운 추천\n",
    "\n",
    "y_true = [1, 2, 3]\n",
    "y_pred = [1, 2, 4, 3, 5]\n",
    "\n",
    "precision = precision_at_k(y_true, y_pred, k)\n",
    "recall = recall_at_k(y_true, y_pred, k)\n",
    "map_ = average_precision_at_k(y_true, y_pred, k)\n",
    "ndcg = ndcg_at_k(y_true, y_pred, k)\n",
    "mrr = mrr_at_k(y_true, y_pred, k)\n",
    "\n",
    "print(f\"Metrics for user {i+1}:\")\n",
    "print(f\"true items of user {i+1}: {y_true}\")\n",
    "print(f\"reco items of user {i+1}: {y_pred}\")\n",
    "print(f\"Precision@{k} = {precision}\")\n",
    "print(f\"Recall@{k} = {recall}\")\n",
    "print(f\"MAP@{k} = {map_}\")\n",
    "print(f\"NDCG@{k} = {ndcg}\")\n",
    "print(f\"MRR@{k} = {mrr}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS class 정의\n",
    "# http://ethen8181.github.io/machine-learning/recsys/1_ALSWR.html\n",
    "\n",
    "\n",
    "class ALS:\n",
    "    # 하이퍼 파라미터 지정\n",
    "    def __init__(self, factors=10, iterations=20, reg=0.01):\n",
    "        self.factors = factors\n",
    "        self.iterations = iterations\n",
    "        self.reg = reg\n",
    "\n",
    "    # 모델 적합 -> 평점 행렬 입력\n",
    "    def fit(self, ratings):\n",
    "        # 랜덤으로 user 수 * latent factor 형태의 행렬 생성\n",
    "        self.user_factors = np.random.random((ratings.shape[0], self.factors))\n",
    "        # 랜덤으로 item 수 * latent factor 형태의 행렬 생성\n",
    "        self.item_factors = np.random.random((ratings.shape[1], self.factors))\n",
    "\n",
    "        # 사전에 지정한 iteration 수에 걸쳐서, 교차로 als_step 진행\n",
    "        for _ in range(self.iterations):\n",
    "            # user_factors 먼저 업데이트\n",
    "            self.user_factors = self.als_step(\n",
    "                ratings, self.user_factors, self.item_factors\n",
    "            )\n",
    "            # 이어서 item_factors 업데이트\n",
    "            self.item_factors = self.als_step(\n",
    "                ratings.T, self.item_factors, self.user_factors\n",
    "            )\n",
    "\n",
    "    # 교차로 업데이트하는 스텝 메서드\n",
    "    def als_step(self, ratings, solve_vecs, fixed_vecs):\n",
    "        # normal equation - 업데이트 되지 않을 user/item feature의 공분산 matrix\n",
    "        # feature가 주어진(고정된) 상태에서 최적의 해를 찾아 그 행렬을 새로운 factors로 사용\n",
    "        # 가령, user_factors가 고정되어 있을 때는 최적의 item_factors를 구하고, 반대도 마찬가지\n",
    "        A = fixed_vecs.T.dot(fixed_vecs) + np.eye(self.factors) * self.reg\n",
    "        b = ratings.dot(fixed_vecs)\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        solve_vecs = b.dot(A_inv)\n",
    "        return solve_vecs\n",
    "\n",
    "    def predict(self):\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00502/online_retail_II.xlsx\"\n",
    "df = pd.read_excel(url)\n",
    "df[\"Customer ID\"] = df[\"Customer ID\"].astype(\"category\")\n",
    "df[\"StockCode\"] = df[\"StockCode\"].astype(\"category\")\n",
    "df = df.rename({\"Customer ID\": \"CustomerID\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Make pivot table and remove users and items with too few interactions\n",
    "interaction_counts = df.groupby(\"CustomerID\").StockCode.count()\n",
    "df = df[df.CustomerID.isin(interaction_counts[interaction_counts > 10].index)]\n",
    "item_counts = df.StockCode.value_counts()\n",
    "df = df[df.StockCode.isin(item_counts[item_counts > 10].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = df.pivot_table(\n",
    "    index=\"CustomerID\", columns=\"StockCode\", fill_value=0, aggfunc=\"size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Make y label as a implicit feedback, with binary value\n",
    "pivot = (pivot > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create train/test split\n",
    "test_ratio = 0.2\n",
    "train = pivot.copy()\n",
    "test = np.zeros(pivot.shape)\n",
    "\n",
    "for user in range(pivot.shape[0]):\n",
    "    test_interactions = np.random.choice(\n",
    "        pivot.values[user, :].nonzero()[0],\n",
    "        size=int(test_ratio * np.sum(pivot.values[user, :])),\n",
    "        replace=False,\n",
    "    )\n",
    "    train.values[user, test_interactions] = 0.0\n",
    "    test[user, test_interactions] = pivot.values[user, test_interactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test matrix into sparse matrix\n",
    "train_csr = coo_matrix(train.values)\n",
    "test_csr = coo_matrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "\n",
    "# using sklearn Truncated SVD\n",
    "svd = TruncatedSVD(n_components=n_latent_factors, random_state=42)\n",
    "train_svd = svd.fit_transform(train_csr)\n",
    "svd_pred = svd.inverse_transform(svd.transform(test_csr))\n",
    "\n",
    "# using svds from scipy\n",
    "u, sigma, vt = svds(train_csr.astype(float), n_latent_factors)\n",
    "svd_pred = np.dot(u, np.dot(np.diag(sigma), vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf-env/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1710: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# NMF\n",
    "model = NMF(n_components=n_latent_factors, init=\"random\", random_state=0)\n",
    "\n",
    "W = model.fit_transform(train_csr)\n",
    "H = model.components_\n",
    "nmf_pred = np.dot(W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ALS model\n",
    "als = ALS(factors=n_latent_factors, iterations=100, reg=0.01)\n",
    "als.fit(train_csr)\n",
    "\n",
    "# predict\n",
    "als_pred = als.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_k = 10\n",
    "\n",
    "# Make sure the predicted scores are in the range [0, 1]\n",
    "predicted_svd = (svd_pred - svd_pred.min()) / (svd_pred.max() - svd_pred.min())\n",
    "predicted_nmf = (nmf_pred - nmf_pred.min()) / (nmf_pred.max() - nmf_pred.min())\n",
    "predicted_als = (als_pred - als_pred.min()) / (als_pred.max() - als_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD RMSE:  0.35862064504336627\n",
      "NMF RMSE:  0.05022406711579663\n",
      "ALS RMSE:  0.3710927687067437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate RMSE for SVD\n",
    "svd_rmse = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_svd))\n",
    "print(\"SVD RMSE: \", svd_rmse)\n",
    "\n",
    "# Calculate RMSE for NMF\n",
    "nmf_rmse = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_nmf))\n",
    "print(\"NMF RMSE: \", nmf_rmse)\n",
    "\n",
    "# Calculate RMSE for ALS\n",
    "als_rmse = np.sqrt(mean_squared_error(test_csr.toarray(), predicted_als))\n",
    "print(\"ALS RMSE: \", als_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svd = [np.argsort(row)[-at_k:] for row in predicted_svd]\n",
    "predicted_nmf = [np.argsort(row)[-at_k:] for row in predicted_nmf]\n",
    "predicted_als = [np.argsort(row)[-at_k:] for row in predicted_als]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 827, 2325, 2333, 2334, 2336,  828, 2335,  112, 2338, 2328]),\n",
       " array([1731, 1870, 1895, 1732, 1804, 1523, 1728, 1805, 1521, 1608]),\n",
       " array([ 544,  431, 1211, 1602,  547, 1210, 2722, 1212, 2721,  546]),\n",
       " array([2336, 2333,  838,  836,  830, 2328,  828, 2335, 2338,  112]),\n",
       " array([1109,  300, 1608,  809,  842, 1108,  834,  836,  838,  830]),\n",
       " array([2803, 4149,  511, 2474, 1166, 1598,  504, 2805,  512,  516]),\n",
       " array([3364, 3337, 1823, 1272, 1819, 1820, 1263, 1821,  563,  564]),\n",
       " array([1269, 1819, 1820, 1272, 1823, 3337, 1263, 1821,  563,  564]),\n",
       " array([ 563, 1608,  564,  547, 1210, 2722, 1602,  546, 1212, 2721]),\n",
       " array([3614, 2030, 2328,  112, 1320, 2031,  793,  796, 1322, 1319])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_svd[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = test_csr.tocsr()\n",
    "true_interactions = [rows.getrow(i).indices for i in range(rows.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rows.shape[0]):\n",
    "    rows.getrow(i).indices\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4632 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows.getrow(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 109,  827,  828, 1205, 1860], dtype=int32),\n",
       " array([ 420, 1019, 1253, 1401, 1416, 1677, 1898, 2407, 2721, 3377, 3387,\n",
       "        3791, 4199, 4267], dtype=int32),\n",
       " array([2113, 2114, 2718, 2722], dtype=int32),\n",
       " array([ 350,  564,  683,  828,  834,  836, 1059, 1267, 1373, 1386, 1545,\n",
       "        1627, 1641, 1730, 1732, 1876, 2013, 4051], dtype=int32),\n",
       " array([1259, 1499, 1882, 2130], dtype=int32),\n",
       " array([1031, 1402, 1403], dtype=int32),\n",
       " array([  80, 1272, 1315, 1317], dtype=int32),\n",
       " array([1060, 1061, 1604, 3770], dtype=int32),\n",
       " array([1207, 1254, 1267, 1279, 1728, 1788, 1804, 1905, 2070, 2258, 2718,\n",
       "        3425, 3750], dtype=int32),\n",
       " array([ 327,  331,  424,  564,  793,  799,  980, 1245, 1322, 1506, 1507,\n",
       "        1509, 1547, 1567, 1569, 1587, 1591, 1592, 1599, 1806, 1833, 1896,\n",
       "        1897, 2006, 2009, 2030, 2135, 2243, 2333, 2338, 2383, 3626, 3936],\n",
       "       dtype=int32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_interactions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Precision@K\": precision_at_k,\n",
    "    \"Recall@K\": recall_at_k,\n",
    "    \"MAP@K\": average_precision_at_k,\n",
    "    \"NDCG@K\": ndcg_at_k,\n",
    "    \"MRR@K\": mrr_at_k,\n",
    "}\n",
    "\n",
    "predictions = {\"SVD\": predicted_svd, \"NMF\": predicted_nmf, \"ALS\": predicted_als}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD:\n",
      "    Precision@K: 0.05660506502395478\n",
      "    Recall@K: 0.06642109159862024\n",
      "    MAP@K: 0.02766157806274923\n",
      "    NDCG@K: 0.06943103476560814\n",
      "    MRR@K: 0.14086532019454662\n",
      "NMF:\n",
      "    Precision@K: 0.051403148528404066\n",
      "    Recall@K: 0.05501968106002313\n",
      "    MAP@K: 0.0234305272015432\n",
      "    NDCG@K: 0.06047878918998058\n",
      "    MRR@K: 0.12413998529672698\n",
      "ALS:\n",
      "    Precision@K: 0.05651380333105039\n",
      "    Recall@K: 0.06621301322885632\n",
      "    MAP@K: 0.027092655415484126\n",
      "    NDCG@K: 0.06872879878209151\n",
      "    MRR@K: 0.13851840987364578\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "average_metrics = {\n",
    "    model: {metric: 0 for metric in metrics.keys()} for model in predictions.keys()\n",
    "}\n",
    "\n",
    "for model, predicted in predictions.items():\n",
    "    for y_true, y_pred in zip(true_interactions, predicted):\n",
    "        if len(y_true) > 0:\n",
    "            for metric_name, metric_fn in metrics.items():\n",
    "                average_metrics[model][metric_name] += metric_fn(y_true, y_pred, K)\n",
    "\n",
    "    for metric_name in metrics.keys():\n",
    "        average_metrics[model][metric_name] /= len(true_interactions)\n",
    "\n",
    "for model, model_metrics in average_metrics.items():\n",
    "    print(f\"{model}:\")\n",
    "    for metric, value in model_metrics.items():\n",
    "        print(f\"    {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
