{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM:\n",
    "    def __init__(self, n_factors=10, learning_rate=0.01, n_epochs=10):\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "        # label encoder는 1부터 카운트하기 때문에, nunique를 지정해 주기 위해 1을 더해 줌\n",
    "        self.n_users = int(np.max(X[:, 0]) + 1)\n",
    "        self.n_items = int(np.max(X[:, 1]) + 1)\n",
    "\n",
    "        # 실제 y label의 평균을 global bias로 설정\n",
    "        self.global_bias = np.mean(y)\n",
    "\n",
    "        # 유저/아이템 피처별 bias를 0으로 셋팅\n",
    "        self.user_bias = np.zeros(self.n_users)\n",
    "        self.item_bias = np.zeros(self.n_items)\n",
    "\n",
    "        # 평균 0, std 0.1인 정규분포에서 유저 및 아이템 팩터 초기화, 각 대상 별 n_factors개의 팩터를 할당\n",
    "        self.user_factors = np.random.normal(\n",
    "            scale=0.1, size=(self.n_users, self.n_factors)\n",
    "        )\n",
    "        self.item_factors = np.random.normal(\n",
    "            scale=0.1, size=(self.n_items, self.n_factors)\n",
    "        )\n",
    "\n",
    "        for epoch in tqdm(range(self.n_epochs), desc=\"Training epoch\"):\n",
    "\n",
    "            # 각 epoch에 따라 다음을 수행\n",
    "            for i in range(X.shape[0]):\n",
    "\n",
    "                # 학습셋 내의 user-item pair를 대상으로 다음을 반복\n",
    "                user, item = int(X[i, 0]), int(X[i, 1])\n",
    "\n",
    "                # 예측 값 생성\n",
    "                prediction = self.predict(user, item)\n",
    "\n",
    "                # 실제 값과 예측 값을 대조함으로써 error 계산 -> loss function 계산에 사용\n",
    "                e = y[i] - prediction\n",
    "\n",
    "                # Loss function을 bias term에 대해 미분 -> (e - bias)로 계산\n",
    "                self.user_bias[user] += self.learning_rate * (e - self.user_bias[user])\n",
    "                self.item_bias[item] += self.learning_rate * (e - self.item_bias[item])\n",
    "\n",
    "                # pairwise term의 Loss function을 latent factor에 대해 미분 -> (e * 상대 factor - 타겟 factor)로 계산\n",
    "                self.user_factors[user] += self.learning_rate * (\n",
    "                    e * self.item_factors[item] - self.user_factors[user]\n",
    "                )\n",
    "                self.item_factors[item] += self.learning_rate * (\n",
    "                    e * self.user_factors[user] - self.item_factors[item]\n",
    "                )\n",
    "\n",
    "            # 전체 로스 계산\n",
    "            loss = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                user, item = int(X[i, 0]), int(X[i, 1])\n",
    "                prediction = self.predict(user, item)\n",
    "                loss += (y[i] - prediction) ** 2\n",
    "\n",
    "            # validation pair에 대해 metrics 계산\n",
    "            y_pred = [self.predict(user, item) for user, item in X_val]\n",
    "            auc_score = roc_auc_score(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch + 1}/{self.n_epochs} - loss: {loss / X.shape[0]} - val_auc: {auc_score} - val_rmse: {rmse}\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        # global bias와 user/item bias를 각각 더해주고, item/user factor를 내적해 준 값을 더해 최종 예측을 생성\n",
    "        prediction = (\n",
    "            self.global_bias\n",
    "            + self.user_bias[user]\n",
    "            + self.item_bias[item]\n",
    "            + np.dot(self.item_factors[item], self.user_factors[user])\n",
    "        )\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "data_path = \"../data/anime/\"\n",
    "\n",
    "anime = pd.read_csv(data_path + \"anime.csv\")\n",
    "rating = pd.read_csv(data_path + \"rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_sampled = rating.sample(100_000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "merged = pd.merge(anime, rating_sampled, on=\"anime_id\", suffixes=[\"_anime\", \"_user\"])\n",
    "merged = merged.dropna()\n",
    "merged = merged[\n",
    "    [\"anime_id\", \"name\", \"genre\", \"type\", \"episodes\", \"rating_user\", \"user_id\"]\n",
    "]\n",
    "\n",
    "# user/item id 인코딩\n",
    "user_enc = LabelEncoder()\n",
    "anime_enc = LabelEncoder()\n",
    "merged[\"user\"] = user_enc.fit_transform(merged[\"user_id\"].values)\n",
    "merged[\"anime\"] = anime_enc.fit_transform(merged[\"anime_id\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 이상의 평점을 갖는 경우 1로, 그 외에는 0으로 인코딩\n",
    "merged[\"rating\"] = [1 if x >= 6 else 0 for x in merged[\"rating_user\"]]\n",
    "\n",
    "# id 정보만을 사용\n",
    "X = merged[[\"user\", \"anime\"]].values\n",
    "y = merged[\"rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17428,  5652],\n",
       "       [ 9387,  5652],\n",
       "       [21969,  5652],\n",
       "       [  698,  5652],\n",
       "       [ 2286,  5652]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  10%|█         | 1/10 [00:00<00:05,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - loss: 0.17251228138950633 - val_auc: 0.6757261649826166 - val_rmse: 0.42144339569157674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  20%|██        | 2/10 [00:01<00:05,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - loss: 0.16271203355763927 - val_auc: 0.7262627548788547 - val_rmse: 0.41517354904063963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  30%|███       | 3/10 [00:01<00:04,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - loss: 0.15502825760634448 - val_auc: 0.7529747318463802 - val_rmse: 0.4101709176646283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  40%|████      | 4/10 [00:02<00:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - loss: 0.1486670735472995 - val_auc: 0.7696407434676042 - val_rmse: 0.4059760587135535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  50%|█████     | 5/10 [00:03<00:03,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - loss: 0.1432518187153025 - val_auc: 0.7809586904116153 - val_rmse: 0.40237741937858496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  60%|██████    | 6/10 [00:03<00:02,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - loss: 0.13855684219156747 - val_auc: 0.7890498027460762 - val_rmse: 0.39924476290321886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  70%|███████   | 7/10 [00:04<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - loss: 0.13443171417506405 - val_auc: 0.7951121675588295 - val_rmse: 0.3964883849827802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  80%|████████  | 8/10 [00:05<00:01,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - loss: 0.13076960480206096 - val_auc: 0.7997820044659742 - val_rmse: 0.3940427040597478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  90%|█████████ | 9/10 [00:05<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - loss: 0.12749130364987202 - val_auc: 0.8034455973543343 - val_rmse: 0.39185787537350736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - loss: 0.1245361800590691 - val_auc: 0.8063895734711979 - val_rmse: 0.3898949314811094\n",
      "sparsity:  0.000459066495809462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 인스턴스 생성 및 학습\n",
    "fm = FM(n_factors=10, learning_rate=0.01, n_epochs=10)\n",
    "fm.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "n_users = int(np.max(X_train[:, 0]) + 1)\n",
    "n_items = int(np.max(X_train[:, 1]) + 1)\n",
    "\n",
    "print(\"sparsity: \", rating_sampled.shape[0] / (n_users * n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.335503459550988"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)[0].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, item):\n",
    "    # global bias와 user/item bias를 각각 더해주고, item/user factor를 내적해 준 값을 더해 최종 예측을 생성\n",
    "    prediction = (\n",
    "        global_bias\n",
    "        + user_bias[user]\n",
    "        + item_bias[item]\n",
    "        + np.dot(item_factors[item], user_factors[user])\n",
    "    )\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "n_factors = 8\n",
    "learning_rate = 0.01\n",
    "\n",
    "# label encoder는 1부터 카운트하기 때문에, nunique를 지정해 주기 위해 1을 더해 줌\n",
    "n_users = int(np.max(X[:, 0]) + 1)\n",
    "n_items = int(np.max(X[:, 1]) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37838 5757\n"
     ]
    }
   ],
   "source": [
    "print(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 y label의 평균을 global bias로 설정\n",
    "global_bias = np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751085021700434"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저/아이템 피처별 bias를 0으로 셋팅\n",
    "user_bias = np.zeros(n_users)\n",
    "item_bias = np.zeros(n_items)\n",
    "\n",
    "# 평균 0, std 0.1인 정규분포에서 유저 및 아이템 팩터 초기화, 각 대상 별 n_factors개의 팩터를 할당\n",
    "user_factors = np.random.normal(scale=0.1, size=(n_users, n_factors))\n",
    "item_factors = np.random.normal(scale=0.1, size=(n_items, n_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.16787083e-01,  3.60830616e-02,  2.89391146e-04,\n",
       "        -9.24351337e-02,  2.01635089e-02, -1.00559995e-01,\n",
       "         6.30785902e-02, -5.32058643e-02],\n",
       "       [ 4.14997168e-02,  1.35890362e-01,  1.97700545e-02,\n",
       "         5.14264723e-02,  3.31253294e-02,  1.55968229e-01,\n",
       "         1.37695507e-01,  3.45388390e-02],\n",
       "       [-1.84834654e-01, -5.16707354e-02, -1.60756178e-02,\n",
       "        -6.09059819e-02,  3.21590321e-01, -8.66452121e-02,\n",
       "         1.64674772e-02,  5.72767135e-02],\n",
       "       [ 4.85516445e-02, -3.36874644e-02, -9.57123884e-03,\n",
       "         1.74577169e-01,  1.38886139e-01, -1.25492445e-01,\n",
       "        -1.75020843e-01,  1.61059549e-01],\n",
       "       [-6.37080819e-02, -5.36736124e-02,  1.42006654e-01,\n",
       "        -1.65720462e-01,  1.46010321e-01, -7.09997938e-04,\n",
       "         9.70037727e-02,  4.46417650e-02],\n",
       "       [-3.33368926e-02, -1.39350618e-01, -8.52916801e-02,\n",
       "        -1.15827694e-02,  1.42509159e-01,  5.20440705e-02,\n",
       "         2.81434865e-02,  6.41861381e-02],\n",
       "       [ 9.97867176e-02,  9.33778649e-02,  7.56762285e-02,\n",
       "        -1.73133927e-01, -7.17743335e-02, -9.73729333e-03,\n",
       "         8.49463119e-02,  2.25647445e-01],\n",
       "       [ 1.03647386e-01, -6.66120582e-02,  1.51883900e-01,\n",
       "        -7.23503026e-02, -1.56837276e-01, -6.64041904e-02,\n",
       "         1.73844179e-01,  2.92691740e-02],\n",
       "       [-1.26282312e-01, -2.08588378e-02,  4.58396314e-02,\n",
       "        -1.10329364e-01,  4.01010755e-02, -1.15760758e-01,\n",
       "         1.66736193e-01, -1.42746345e-01],\n",
       "       [-6.77515885e-02, -1.97447218e-02, -1.49897033e-01,\n",
       "         2.87529649e-02, -4.79317333e-02, -5.55465575e-02,\n",
       "        -1.15525467e-01,  1.51691365e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - loss: 0.1877399559500641 - val_auc: 0.5038561224091495 - val_rmse: 0.4318023349938312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs), desc=\"Training epoch\"):\n",
    "\n",
    "    # 각 epoch에 따라 다음을 수행\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        # 학습셋 내의 user-item pair를 대상으로 다음을 반복\n",
    "        user, item = int(X[i, 0]), int(X[i, 1])\n",
    "\n",
    "        # 예측 값 생성\n",
    "        prediction = predict(user, item)\n",
    "\n",
    "        # 실제 값과 예측 값을 대조함으로써 error 계산 -> loss function 계산에 사용\n",
    "        e = y[i] - prediction\n",
    "\n",
    "        # Loss function을 bias term에 대해 미분 -> (e - bias)로 계산\n",
    "        user_bias[user] += learning_rate * (e - user_bias[user])\n",
    "        item_bias[item] += learning_rate * (e - item_bias[item])\n",
    "\n",
    "        # pairwise term의 Loss function을 latent factor에 대해 미분 -> (e * 상대 factor - 타겟 factor)로 계산\n",
    "        user_factors[user] += learning_rate * (\n",
    "            e * item_factors[item] - user_factors[user]\n",
    "        )\n",
    "        item_factors[item] += learning_rate * (\n",
    "            e * user_factors[user] - item_factors[item]\n",
    "        )\n",
    "        break\n",
    "\n",
    "    # 전체 로스 계산\n",
    "    loss = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        user, item = int(X[i, 0]), int(X[i, 1])\n",
    "        prediction = predict(user, item)\n",
    "        loss += (y[i] - prediction) ** 2\n",
    "\n",
    "    # validation pair에 대해 metric 계산\n",
    "    y_pred = [predict(user, item) for user, item in X_val]\n",
    "    auc_score = roc_auc_score(y_val, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{n_epochs} - loss: {loss / X.shape[0]} - val_auc: {auc_score} - val_rmse: {rmse}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_sampled = rating.sample(1_000_000, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "merged = pd.merge(anime, rating_sampled, on=\"anime_id\", suffixes=[\"_anime\", \"_user\"])\n",
    "merged = merged.dropna()\n",
    "merged = merged[\n",
    "    [\"anime_id\", \"name\", \"genre\", \"type\", \"episodes\", \"rating_user\", \"user_id\"]\n",
    "]\n",
    "\n",
    "# Create features from user and anime\n",
    "user_enc = LabelEncoder()\n",
    "anime_enc = LabelEncoder()\n",
    "merged[\"user\"] = user_enc.fit_transform(merged[\"user_id\"].values)\n",
    "merged[\"anime\"] = anime_enc.fit_transform(merged[\"anime_id\"].values)\n",
    "\n",
    "# Transform ratings to binary\n",
    "merged[\"rating\"] = [1 if x >= 6 else 0 for x in merged[\"rating_user\"]]\n",
    "\n",
    "# Prepare the data\n",
    "X = merged[[\"user\", \"anime\"]].values\n",
    "y = merged[\"rating\"].values\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  10%|█         | 1/10 [00:06<00:59,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - loss: 0.14499846829027416 - val_auc: 0.8726614411254024 - val_rmse: 0.38639264875665236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  20%|██        | 2/10 [00:13<00:54,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - loss: 0.1306936824926087 - val_auc: 0.8918814912429671 - val_rmse: 0.3689809424518295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  30%|███       | 3/10 [00:20<00:47,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - loss: 0.12312511012356796 - val_auc: 0.8981367441563521 - val_rmse: 0.35953265172218785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  40%|████      | 4/10 [00:27<00:40,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - loss: 0.11847636370694407 - val_auc: 0.9011911926225337 - val_rmse: 0.3536676501651579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  50%|█████     | 5/10 [00:33<00:33,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - loss: 0.11536105534240204 - val_auc: 0.9029611991184587 - val_rmse: 0.34972451048870473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  60%|██████    | 6/10 [00:40<00:26,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - loss: 0.11314692717135284 - val_auc: 0.9040822780619878 - val_rmse: 0.3469248131040382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  70%|███████   | 7/10 [00:46<00:19,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - loss: 0.11150428913009756 - val_auc: 0.9048299277663714 - val_rmse: 0.3448553060266333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  80%|████████  | 8/10 [00:52<00:12,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - loss: 0.11024483061861408 - val_auc: 0.9053429440798433 - val_rmse: 0.34327707410154545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  90%|█████████ | 9/10 [00:59<00:06,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - loss: 0.10925354608658962 - val_auc: 0.9057030147563483 - val_rmse: 0.3420430198203784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 10/10 [01:05<00:00,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - loss: 0.10845647188537122 - val_auc: 0.9059576675350323 - val_rmse: 0.3410580442946167\n",
      "sparsity:  0.001778654950320264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the FM model\n",
    "fm = FM(n_factors=10, learning_rate=0.01, n_epochs=10)\n",
    "fm.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "n_users = int(np.max(X_train[:, 0]) + 1)\n",
    "n_items = int(np.max(X_train[:, 1]) + 1)\n",
    "\n",
    "print(\"sparsity: \", rating_sampled.shape[0] / (n_users * n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.611678648001009"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)[0].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:   7%|▋         | 2/30 [00:00<00:01, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - loss: 0.17896276075115986 - val_auc: 0.5213486013205321 - val_rmse: 0.44371553866886226\n",
      "Epoch 2/30 - loss: 0.1704888519134453 - val_auc: 0.5425217696405218 - val_rmse: 0.44240248015869144\n",
      "Epoch 3/30 - loss: 0.16306499966540552 - val_auc: 0.5580287710120889 - val_rmse: 0.44137525441410524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  20%|██        | 6/30 [00:00<00:01, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - loss: 0.1564585873202387 - val_auc: 0.56969028101177 - val_rmse: 0.4405369609240656\n",
      "Epoch 5/30 - loss: 0.15051408598645713 - val_auc: 0.5784032407259736 - val_rmse: 0.43983279201065684\n",
      "Epoch 6/30 - loss: 0.14512006384487272 - val_auc: 0.5852011100124398 - val_rmse: 0.43922869154933847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  27%|██▋       | 8/30 [00:00<00:01, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - loss: 0.14019275688645522 - val_auc: 0.5904168926031068 - val_rmse: 0.43870198610839517\n",
      "Epoch 8/30 - loss: 0.13566697964047134 - val_auc: 0.5947727345220248 - val_rmse: 0.4382367968597223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  33%|███▎      | 10/30 [00:00<00:01, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - loss: 0.1314906681337141 - val_auc: 0.5982660840164588 - val_rmse: 0.43782157321359505\n",
      "Epoch 10/30 - loss: 0.12762139013997256 - val_auc: 0.6012286689419795 - val_rmse: 0.43744766239747773\n",
      "Epoch 11/30 - loss: 0.1240240004724283 - val_auc: 0.6036706963095276 - val_rmse: 0.4371084280733984\n",
      "Epoch 12/30 - loss: 0.1206690021626954 - val_auc: 0.6058575484035598 - val_rmse: 0.4367986804940817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  47%|████▋     | 14/30 [00:01<00:01, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - loss: 0.11753136359496485 - val_auc: 0.6076692928455233 - val_rmse: 0.43651429362238275\n",
      "Epoch 14/30 - loss: 0.11458964176308897 - val_auc: 0.6092947593378202 - val_rmse: 0.43625193972747245\n",
      "Epoch 15/30 - loss: 0.1118253178405116 - val_auc: 0.6106089119964275 - val_rmse: 0.4360089006432341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  60%|██████    | 18/30 [00:01<00:00, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 - loss: 0.10922228411665047 - val_auc: 0.6119013747567861 - val_rmse: 0.43578293064944984\n",
      "Epoch 17/30 - loss: 0.106766441421528 - val_auc: 0.6129743867819208 - val_rmse: 0.43557215503899105\n",
      "Epoch 18/30 - loss: 0.10444537885098651 - val_auc: 0.614085675098083 - val_rmse: 0.4353749939063813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  67%|██████▋   | 20/30 [00:01<00:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 - loss: 0.10224811588079026 - val_auc: 0.6149162706133776 - val_rmse: 0.4351901041013108\n",
      "Epoch 20/30 - loss: 0.10016489250412192 - val_auc: 0.6157175209722178 - val_rmse: 0.43501633447948973\n",
      "Epoch 21/30 - loss: 0.09818699683479541 - val_auc: 0.6163988389525055 - val_rmse: 0.4348526910267806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  80%|████████  | 24/30 [00:01<00:00, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 - loss: 0.09630662228950564 - val_auc: 0.6170163631144142 - val_rmse: 0.43469830940681337\n",
      "Epoch 23/30 - loss: 0.09451674837199214 - val_auc: 0.6178201652259896 - val_rmse: 0.4345524331531713\n",
      "Epoch 24/30 - loss: 0.09281104047052745 - val_auc: 0.6183509297949028 - val_rmse: 0.4344143961973805\n",
      "Epoch 25/30 - loss: 0.09118376510515437 - val_auc: 0.6189110395202705 - val_rmse: 0.43428360875853633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch:  93%|█████████▎| 28/30 [00:02<00:00, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 - loss: 0.08962971782813926 - val_auc: 0.6195119772894007 - val_rmse: 0.4341595458617981\n",
      "Epoch 27/30 - loss: 0.08814416156209195 - val_auc: 0.6198628432904851 - val_rmse: 0.4340417379292712\n",
      "Epoch 28/30 - loss: 0.08672277360525645 - val_auc: 0.620337469299225 - val_rmse: 0.4339297630169558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 100%|██████████| 30/30 [00:02<00:00, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 - loss: 0.0853615998777897 - val_auc: 0.6207113010749259 - val_rmse: 0.43382324036849007\n",
      "Epoch 30/30 - loss: 0.08405701525175381 - val_auc: 0.6211246850180218 - val_rmse: 0.4337218250294395\n",
      "sparsity:  0.00042599559750589803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rating_sampled = rating.sample(10_000, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "merged = pd.merge(anime, rating_sampled, on=\"anime_id\", suffixes=[\"_anime\", \"_user\"])\n",
    "merged = merged.dropna()\n",
    "merged = merged[\n",
    "    [\"anime_id\", \"name\", \"genre\", \"type\", \"episodes\", \"rating_user\", \"user_id\"]\n",
    "]\n",
    "\n",
    "# Create features from user and anime\n",
    "user_enc = LabelEncoder()\n",
    "anime_enc = LabelEncoder()\n",
    "merged[\"user\"] = user_enc.fit_transform(merged[\"user_id\"].values)\n",
    "merged[\"anime\"] = anime_enc.fit_transform(merged[\"anime_id\"].values)\n",
    "\n",
    "# Transform ratings to binary\n",
    "merged[\"rating\"] = [1 if x >= 6 else 0 for x in merged[\"rating_user\"]]\n",
    "\n",
    "# Prepare the data\n",
    "X = merged[[\"user\", \"anime\"]].values\n",
    "y = merged[\"rating\"].values\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the FM model\n",
    "fm = FM(n_factors=20, learning_rate=0.01, n_epochs=30)\n",
    "fm.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "\n",
    "n_users = int(np.max(X_train[:, 0]) + 1)\n",
    "n_items = int(np.max(X_train[:, 1]) + 1)\n",
    "\n",
    "print(\"sparsity: \", rating_sampled.shape[0] / (n_users * n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1484352569623888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)[0].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
